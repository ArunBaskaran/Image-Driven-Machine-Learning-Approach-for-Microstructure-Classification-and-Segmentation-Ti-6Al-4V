{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local installation of segmentation-models, if not already included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install segmentation-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import *\n",
    "import keras.backend as K\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from segmentation_models import Unet\n",
    "from segmentation_models import get_preprocessing\n",
    "from segmentation_models.losses import bce_jaccard_loss\n",
    "from segmentation_models.metrics import iou_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the image and mask paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs=15 # define the number of epochs\n",
    "\n",
    "image_lam_mask_paths = [(\"../Images1/image_%d.png\"%i,\n",
    "                     \"lam_masks/mask_%d.png\"%i) for i in range(25,45)] \n",
    "                     # store the image file paths for the training data\n",
    "    \n",
    "image_dup_mask_paths = [(\"../Images1/image_%d.png\"%i,\n",
    "                     \"dup_masks/mask_%d.png\"%i) for i in range(501,521)] \n",
    "\n",
    "# divide the data into training and test data\n",
    "test_lam_paths = image_lam_mask_paths[:int(4)]\n",
    "train_lam_paths = image_lam_mask_paths[int(4):]\n",
    "test_dup_paths = image_dup_mask_paths[:int(4)]\n",
    "train_dup_paths = image_dup_mask_paths[int(4):]\n",
    "num_train_images = len(train_lam_paths) + len(train_dup_paths)\n",
    "num_test_images = len(test_lam_paths) + len(test_dup_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the functions to read images with equiaxed and lamellar morphologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 256\n",
    "def read_dup_data(img_mask_path):\n",
    "    PIL_image = Image.open(img_mask_path[0])\n",
    "    img_in = np.array(PIL_image.convert('L'))\n",
    "    img_in = cv2.resize(img_in, (s,s), interpolation=cv2.INTER_CUBIC)\n",
    "    thi, img_in = cv2.threshold(img_in,np.median(img_in),255,cv2.THRESH_BINARY)\n",
    "    img_in = 255 - img_in\n",
    "    img_in = cv2.medianBlur(img_in, 3)\n",
    "    #plt.imshow(img_in)\n",
    "    #img_in = np.reshape(img_in, (np.shape(img_in)[0],np.shape(img_in)[1],1))\n",
    "    img_in = np.reshape(img_in, (s,s,1))\n",
    "    PIL_mask = Image.open(img_mask_path[1])\n",
    "    mask_in = np.array(PIL_mask.convert('L'))\n",
    "    mask_in = cv2.resize(mask_in, (s,s), interpolation=cv2.INTER_CUBIC)\n",
    "    #plt.imshow(mask_in)\n",
    "    #mask_in = np.reshape(mask_in, (np.shape(mask_in)[0],np.shape(mask_in)[1],1))\n",
    "    thi, mask_in = cv2.threshold(mask_in,np.median(mask_in),255,cv2.THRESH_BINARY)\n",
    "    mask_in = mask_in/255\n",
    "    mask_in = mask_in*2\n",
    "    mask_in = np.reshape(mask_in, (s,s,1))\n",
    "    mask_in = tf.keras.utils.to_categorical(mask_in, num_classes = 3, dtype =\"uint8\")\n",
    "    return (img_in, mask_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lam_data(img_mask_path):\n",
    "    PIL_image = Image.open(img_mask_path[0])\n",
    "    img_in = np.array(PIL_image.convert('L'))\n",
    "    img_in = cv2.resize(img_in, (s,s), interpolation=cv2.INTER_CUBIC)\n",
    "    #thi, img_in = cv2.threshold(img_in,np.median(img_in),255,cv2.THRESH_BINARY)\n",
    "    #img_in = 255 - img_in\n",
    "    img_in = cv2.blur(img_in, (3,3))\n",
    "    img_in = cv2.medianBlur(img_in, 3)\n",
    "    #thi, img_in = cv2.threshold(img_in,np.median(img_in),255,cv2.THRESH_BINARY)\n",
    "    #img_in = cv2.blur(img_in, (5,5))\n",
    "    img_in = np.reshape(img_in, (s,s,1))\n",
    "    PIL_mask = Image.open(img_mask_path[1])\n",
    "    mask_in = np.array(PIL_mask.convert('L'))\n",
    "    mask_in = cv2.resize(mask_in, (s,s), interpolation=cv2.INTER_CUBIC)\n",
    "    thi, mask_in = cv2.threshold(mask_in,np.median(mask_in),255,cv2.THRESH_BINARY)\n",
    "    mask_in = mask_in/255\n",
    "  #plt.imshow(mask_in)\n",
    "    mask_in = np.reshape(mask_in, (s,s,1))\n",
    "    mask_in = tf.keras.utils.to_categorical(mask_in, num_classes = 3, dtype =\"uint8\")\n",
    "    return (img_in, mask_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the images and masks from the pre-defined paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_imgs = np.zeros((num_train_images,)+(s,s)+(1,)) # define the input images for the model\n",
    "out_masks = np.zeros((num_train_images,)+(s,s)+(3,)) # define the input masks for the model\n",
    "for i, img_mask_path in enumerate(train_lam_paths):\n",
    "    img, mask = read_lam_data(img_mask_path) # import images, save as array, crop and resize the image to (256,256,1)\n",
    "    out_imgs[i,...] = img # create single array of images\n",
    "    out_masks[i,...] = mask # create single array of masks\n",
    "\n",
    "flag = i\n",
    "    \n",
    "for i, img_mask_path in enumerate(train_dup_paths):\n",
    "    img, mask = read_dup_data(img_mask_path) # import images, save as array, crop and resize the image to (256,256,1)\n",
    "    out_imgs[i+flag+1,...] = img # create single array of images\n",
    "    out_masks[i+flag+1,...] = mask # create single array of masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the exact model to load, specify the dataset of pre-training, & preprocess the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'resnet34'\n",
    "preprocess_input = get_preprocessing(BACKBONE)\n",
    "\n",
    "x_train = preprocess_input(out_imgs)\n",
    "N = 1\n",
    "\n",
    "base_model = Unet(BACKBONE, classes = 3, encoder_weights='imagenet')\n",
    "\n",
    "inp = Input(shape=(None, None, N))\n",
    "l1 = Conv2D(3, (1, 1))(inp) # map N channels data to 3 channels\n",
    "out = base_model(l1)\n",
    "\n",
    "model = Model(inp, out, name=base_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the compiled model to the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train, y=out_masks, batch_size=9, epochs=20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process the testing data\n",
    "out_imgs = np.zeros((num_test_images,)+(s,s)+(1,))\n",
    "out_masks = np.zeros((num_test_images,)+(s,s)+(3,))\n",
    "for i, img_mask_path in enumerate(test_lam_paths):\n",
    "    img, mask = read_lam_data(img_mask_path)\n",
    "    out_imgs[i,...] = img\n",
    "    out_masks[i,...] = mask\n",
    "    \n",
    "flag = i\n",
    "\n",
    "for i, img_mask_path in enumerate(test_dup_paths):\n",
    "    img, mask = read_dup_data(img_mask_path)\n",
    "    out_imgs[i+flag+1,...] = img\n",
    "    out_masks[i+flag+1,...] = mask\n",
    "\n",
    "# makes a prediction for our test images using the trained model\n",
    "prediction = model.predict_on_batch(out_imgs)\n",
    "\n",
    "#example_pred = prediction[0].reshape(s,s)\n",
    "plt.subplot(131), plt.imshow(prediction[0][:,:,0], 'gray')\n",
    "plt.subplot(132), plt.imshow(prediction[0][:,:,1], 'gray')\n",
    "plt.subplot(133), plt.imshow(prediction[0][:,:,2], 'gray')\n",
    "\n",
    "#print(np.shape(prediction[0][:,:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(141), plt.imshow(prediction[7][:,:,0], 'gray')\n",
    "plt.subplot(142), plt.imshow(prediction[7][:,:,1], 'gray')\n",
    "plt.subplot(143), plt.imshow(prediction[7][:,:,2], 'gray')\n",
    "plt.subplot(144), plt.imshow(out_imgs[7], 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('lam_mask_c0.png', (prediction[0][:,:,0]*256).astype('uint8'))\n",
    "cv2.imwrite('lam_mask_c1.png', (prediction[0][:,:,1]*256).astype('uint8'))\n",
    "cv2.imwrite('lam_mask_c2.png', (prediction[0][:,:,2]*256).astype('uint8'))\n",
    "\n",
    "cv2.imwrite('dup_mask_c0.png', (prediction[7][:,:,0]*256).astype('uint8'))\n",
    "cv2.imwrite('dup_mask_c1.png', (prediction[7][:,:,1]*256).astype('uint8'))\n",
    "cv2.imwrite('dup_mask_c2.png', (prediction[7][:,:,2]*256).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_img = np.reshape(out_imgs[0], (1,256,256,1))\n",
    "\n",
    "s = time.time()\n",
    "prediction = model.predict_on_batch(example_img)\n",
    "f = time.time()\n",
    "print(f-s)\n",
    "#example_pred = prediction[0].reshape(s,s)\n",
    "plt.subplot(131), plt.imshow(prediction[0][:,:,0], 'gray')\n",
    "plt.subplot(132), plt.imshow(prediction[0][:,:,1], 'gray')\n",
    "plt.subplot(133), plt.imshow(prediction[0][:,:,2], 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
