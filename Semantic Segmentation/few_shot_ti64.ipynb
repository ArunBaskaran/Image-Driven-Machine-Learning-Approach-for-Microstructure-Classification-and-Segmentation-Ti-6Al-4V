{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install segmentation-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import watershed\n",
    "from skimage import exposure\n",
    "from skimage.filters import sobel\n",
    "from sklearn.metrics import jaccard_score\n",
    "import random\n",
    "import time\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import *\n",
    "import keras.backend as K\n",
    "from random import shuffle\n",
    "\n",
    "from segmentation_models import Unet\n",
    "from segmentation_models import get_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(img):\n",
    "    return 0.5*img + 0.5*(np.roll(img, +1, axis=0) + np.roll(img, -1, axis=0) +\n",
    "        np.roll(img, +1, axis=1) + np.roll(img, -1, axis=1) )\n",
    "\n",
    "def returnIndex(a , value):\n",
    "    k = np.size(a)\n",
    "    for i in range(k):\n",
    "        if(a[i]==value):\n",
    "            return i\n",
    "        \n",
    "def duplex_segmentation(img_path):\n",
    "    area_frac_duplex=[]\n",
    "    duplex_image_id=[]\n",
    "    image = Image.open(img_path).convert('F')\n",
    "    image = np.copy(np.reshape(np.array(image), image.size[::-1])/255.)   \n",
    "    image = exposure.equalize_adapthist(image, clip_limit=8.3)\n",
    "    image = (smooth(smooth(image)))\n",
    "    image_copy = image\n",
    "    markers = np.zeros_like(image)\n",
    "    markers[image > np.median(image) - 0.10*np.std(image)] = 1     \n",
    "    markers[image < np.median(image) - 0.10*np.std(image)] = 2\n",
    "    fig, (ax1) = plt.subplots(1, sharex=True, sharey=True)\n",
    "    elevation_map = sobel(image)\n",
    "    segmentation = morphology.watershed(elevation_map, markers)\n",
    "    segmentation = ndi.binary_fill_holes(segmentation - 1)\n",
    "    labeled_grains, _ = ndi.label(segmentation)\n",
    "    return np.array(segmentation)\n",
    "\n",
    "def lamellar_segmentation(img_path):\n",
    "    s = 604\n",
    "    PIL_image = Image.open(img_path)\n",
    "    img_in = np.array(PIL_image.convert('L'))\n",
    "    img_in = cv2.resize(img_in, (s,s), interpolation=cv2.INTER_CUBIC)\n",
    "    img_in = cv2.blur(img_in, (3,3))\n",
    "    img_in = cv2.medianBlur(img_in, 3)\n",
    "    thi, img_in = cv2.threshold(img_in,np.median(img_in),255,cv2.THRESH_BINARY)\n",
    "    return np.array(img_in)\n",
    "\n",
    "def read_equi_data(img_mask_path):\n",
    "    PIL_image = Image.open(img_mask_path[0])\n",
    "    img_in = np.array(PIL_image.convert('L'))\n",
    "    img_in = cv2.resize(img_in, (s,s), interpolation=cv2.INTER_CUBIC)\n",
    "    thi, img_in = cv2.threshold(img_in,np.median(img_in),255,cv2.THRESH_BINARY)\n",
    "    img_in = 255 - img_in\n",
    "    img_in = cv2.medianBlur(img_in, 3)\n",
    "    img_in = np.reshape(img_in, (s,s,1))\n",
    "    PIL_mask = Image.open(img_mask_path[1])\n",
    "    mask_in = np.array(PIL_mask.convert('L'))\n",
    "    mask_in = cv2.resize(mask_in, (s,s), interpolation=cv2.INTER_CUBIC)\n",
    "    thi, mask_in = cv2.threshold(mask_in,np.median(mask_in),255,cv2.THRESH_BINARY)\n",
    "    mask_in = mask_in/255\n",
    "    mask_in = mask_in*2\n",
    "    mask_in = np.reshape(mask_in, (s,s,1))\n",
    "    mask_in = tf.keras.utils.to_categorical(mask_in, num_classes = 3, dtype =\"uint8\")\n",
    "    return (img_in, mask_in)\n",
    "\n",
    "def read_lam_data(img_mask_path):\n",
    "    PIL_image = Image.open(img_mask_path[0])\n",
    "    img_in = np.array(PIL_image.convert('L'))\n",
    "    img_in = cv2.resize(img_in, (s,s), interpolation=cv2.INTER_CUBIC)\n",
    "    img_in = cv2.blur(img_in, (3,3))\n",
    "    img_in = cv2.medianBlur(img_in, 3)\n",
    "    img_in = np.reshape(img_in, (s,s,1))\n",
    "    PIL_mask = Image.open(img_mask_path[1])\n",
    "    mask_in = np.array(PIL_mask.convert('L'))\n",
    "    mask_in = cv2.resize(mask_in, (s,s), interpolation=cv2.INTER_CUBIC)\n",
    "    thi, mask_in = cv2.threshold(mask_in,np.median(mask_in),255,cv2.THRESH_BINARY)\n",
    "    mask_in = mask_in/255\n",
    "    mask_in = np.reshape(mask_in, (s,s,1))\n",
    "    mask_in = tf.keras.utils.to_categorical(mask_in, num_classes = 3, dtype =\"uint8\")\n",
    "    return (img_in, mask_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_equi_training_samples = 10\n",
    "for i in range(1, num_equi_training_samples + 1):\n",
    "    file_id = str(num)\n",
    "    img_path = 'equi_images/image_' + file_id + '.png'\n",
    "    res = duplex_segmentation(img_path)\n",
    "    res_for_cv2 = (res*255.).astype('uint8')\n",
    "    outfile = 'equi_masks/mask_' + file_id + '.png'\n",
    "    cv2.imwrite(outfile, res_for_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lam_training_samples = 10\n",
    "for num in range(1, num_lam_training_samples + 1):\n",
    "    file_id = str(num)\n",
    "    img_path = 'lam_images/image_' + file_id + '.png'\n",
    "    res = lamellar_segmentation(img_path)\n",
    "    res_for_cv2 = res #(res*255.).astype('uint8')\n",
    "    outfile = 'lam_masks/mask_' + file_id + '.png'\n",
    "    cv2.imwrite(outfile, res_for_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_equi_mask_paths = [(\"equi_images/image_%d.png\"%i,\n",
    "                     \"equi_masks/mask_%d.png\"%i) for i in range(1,num_equi_training_samples + 1)] \n",
    "            \n",
    "    \n",
    "train_lam_mask_paths = [(\"lam_images/image_%d.png\"%i,\n",
    "                     \"lam_masks/mask_%d.png\"%i) for i in range(1,num_lam_training_samples + 1)] \n",
    "\n",
    "\n",
    "train_lam_paths = train_lam_mask_paths[int(1):]\n",
    "train_equi_paths = train_equi_mask_paths[int(1):]\n",
    "num_train_images = len(train_lam_paths) + len(train_equi_paths)\n",
    "num_test_images = len(test_lam_paths) + len(test_equi_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_imgs = np.zeros((num_train_images,)+(s,s)+(1,)) \n",
    "out_masks = np.zeros((num_train_images,)+(s,s)+(3,)) \n",
    "for i, img_mask_path in enumerate(train_lam_paths):\n",
    "    img, mask = read_lam_data(img_mask_path) # import images, save as array, crop and resize the image to (256,256,1)\n",
    "    out_imgs[i,...] = img # create single array of images\n",
    "    out_masks[i,...] = mask # create single array of masks\n",
    "\n",
    "flag = len(train_lam_paths)\n",
    "    \n",
    "for i, img_mask_path in enumerate(train_equi_paths):\n",
    "    img, mask = read_equi_data(img_mask_path) # import images, save as #array, crop and resize the image to (256,256,1)\n",
    "    out_imgs[i+flag,...] = img # create single array of images\n",
    "    out_masks[i+flag,...] = mask # create single array of masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'resnet34'\n",
    "preprocess_input = get_preprocessing(BACKBONE)\n",
    "\n",
    "x_train = preprocess_input(out_imgs)\n",
    "\n",
    "N = 1\n",
    "\n",
    "base_model = Unet(BACKBONE, classes = 3, activation='softmax', encoder_weights='imagenet')\n",
    "\n",
    "inp = Input(shape=(None, None, N))\n",
    "l1 = Conv2D(3, (1, 1))(inp) \n",
    "out = base_model(l1)\n",
    "#out = BatchNormalization()(out)\n",
    "\n",
    "model = Model(inp, out, name=base_model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 0\n",
    "overall_acc = []\n",
    "overall_iou = []\n",
    "\n",
    "out_imgs = np.zeros((num_train_images,)+(s,s)+(1,)) # define the input images for the model\n",
    "out_masks = np.zeros((num_train_images,)+(s,s)+(3,)) # define the input masks for the model\n",
    "for i, img_mask_path in enumerate(train_lam_paths):\n",
    "    img, mask = read_lam_data(img_mask_path) # import images, save as array, crop and resize the image to (256,256,1)\n",
    "    out_imgs[i,...] = img # create single array of images\n",
    "    out_masks[i,...] = mask # create single array of masks\n",
    "\n",
    "flag = len(train_lam_paths)\n",
    "    \n",
    "for i, img_mask_path in enumerate(train_equi_paths):\n",
    "    img, mask = read_equi_data(img_mask_path) # import images, save as #array, crop and resize the image to (256,256,1)\n",
    "    out_imgs[i+flag,...] = img # create single array of images\n",
    "    out_masks[i+flag,...] = mask # create single array of masks\n",
    "        \n",
    "BACKBONE = 'resnet34'\n",
    "preprocess_input = get_preprocessing(BACKBONE)\n",
    "x_train = preprocess_input(out_imgs)\n",
    "\n",
    "model.fit(x=x_train, y=out_masks, batch_size=3, epochs=5, verbose = 1)\n",
    "\n",
    "steps += 20\n",
    "\n",
    "test_equi_mask_paths = [(\"equi_images/image_%d.png\"%i,\n",
    "                     \"equi_masks/mask_%d.png\"%i) for i in range(num_equi_training_samples + 1, num_equi_training_samples + 11)] \n",
    "                \n",
    "test_lam_mask_paths = [(\"lam_images/image_%d.png\"%i,\n",
    "                     \"lam_masks/mask_%d.png\"%i) for i in range(num_lam_training_samples + 1, num_lam_training_samples + 11)] \n",
    "    \n",
    "num_test_images = len(test_lam_mask_paths) + len(test_equi_mask_paths)\n",
    "    \n",
    "out_imgs = np.zeros((num_test_images,)+(s,s)+(1,))\n",
    "out_masks = np.zeros((num_test_images,)+(s,s)+(3,))\n",
    "for i, img_mask_path in enumerate(test_lam_mask_paths):\n",
    "    img, mask = read_lam_data(img_mask_path)\n",
    "    out_imgs[i,...] = img\n",
    "    out_masks[i,...] = mask\n",
    "    \n",
    "flag = len(test_lam_mask_paths)\n",
    "\n",
    "for i, img_mask_path in enumerate(test_equi_mask_paths):\n",
    "    img, mask = read_equi_data(img_mask_path)\n",
    "    out_imgs[i+flag,...] = img\n",
    "    out_masks[i+flag,...] = mask\n",
    "\n",
    "    \n",
    "prediction = model.predict_on_batch(out_imgs)\n",
    "curr_round_acc = []\n",
    "curr_round_iou = []\n",
    "for i in range(len(test_lam_mask_paths)):\n",
    "    img2 = Image.open(test_lam_mask_paths[i][1])\n",
    "    img2 = np.array(img2.convert('L'))\n",
    "    img2 = cv2.resize(img2, (256,256), interpolation=cv2.INTER_CUBIC)\n",
    "    thi, img2 = cv2.threshold(img2, np.median(img2),255,cv2.THRESH_BINARY)\n",
    "    img2 = img2/255\n",
    "    img2 = img2.astype('uint8')\n",
    "    img_pred = prediction[i][:,:,1]\n",
    "    img_pred = cv2.resize(img_pred, (256,256), interpolation=cv2.INTER_CUBIC)\n",
    "    thi, img_pred = cv2.threshold(img_pred, np.median(img_pred),255,cv2.THRESH_BINARY)\n",
    "    img_pred = img_pred/255\n",
    "    img_pred = img_pred.astype('uint8')\n",
    "        \n",
    "    iou = jaccard_score(img2, img_pred, average='weighted')\n",
    "    curr_round_iou.append(iou)\n",
    "    diff = (img2 == img_pred).astype('uint8')\n",
    "    accuracy = np.sum(diff)/(256*256)\n",
    "    curr_round_acc.append(accuracy)\n",
    "        \n",
    "for i in range(len(test_lam_mask_paths), num_test_images):\n",
    "    img2 = Image.open(test_dup_mask_paths[i- len(test_lam_mask_paths)][1])\n",
    "    img2 = np.array(img2.convert('L'))\n",
    "    img2 = cv2.resize(img2, (256,256), interpolation=cv2.INTER_CUBIC)\n",
    "    thi, img2 = cv2.threshold(img2, np.median(img2),255,cv2.THRESH_BINARY)\n",
    "    img2 = img2/255\n",
    "    img2 = img2.astype('uint8')\n",
    "    img_pred = prediction[i][:,:,1]\n",
    "    img_pred = cv2.resize(img_pred, (256,256), interpolation=cv2.INTER_CUBIC)\n",
    "    thi, img_pred = cv2.threshold(img_pred, np.median(img_pred),255,cv2.THRESH_BINARY)\n",
    "    img_pred = img_pred/255\n",
    "    img_pred = img_pred.astype('uint8')\n",
    "        \n",
    "    iou = jaccard_score(img2, img_pred, average='weighted')\n",
    "    curr_round_iou.append(iou)\n",
    "    diff = (img2 == img_pred).astype('uint8')\n",
    "    accuracy = np.sum(diff)/(256*256)\n",
    "    curr_round_acc.append(accuracy)\n",
    "        \n",
    "overall_acc.append(curr_round_acc)\n",
    "overall_iou.append(curr_round_iou)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
